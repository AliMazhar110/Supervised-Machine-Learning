{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks: Step by Step"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Welcome to Course 4's first assignment! In this assignment, you will implement convolutional (CONV) and pooling (POOL) layers in numpy, including both forward propagation and (optionally) backward propagation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's first import all the packages that you will need during this assignment.\n",
    "▪️ numpy is the fundamental package for scientific computing with Python.\n",
    "\n",
    "▪️ matplotlib is a library to plot graphs in Python.\n",
    "\n",
    "▪️ np.random.seed(1) is used to keep all the random function calls consistent. This helps to grade your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams[\"image.interpolation\"] = \"nearest\"\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
    "    as illustrated in Figure 1.\n",
    "    \n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)))\n",
    "\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = \n",
      " (4, 3, 3, 2)\n",
      "x_pad.shape = \n",
      " (4, 9, 9, 2)\n",
      "x[1,1] = \n",
      " [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] = \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25f7b5b1750>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4,3,3,2)\n",
    "x_pad = zero_pad(x,3)\n",
    "print(\"x.shape = \\n\", x.shape)\n",
    "print(\"x_pad.shape = \\n\", x_pad.shape)\n",
    "print(\"x[1,1] = \\n\", x[1,1])\n",
    "print(\"x_pad[1,1] = \\n\", x_pad[1,1])\n",
    "\n",
    "print(x_pad[0,0:2,:,0])\n",
    "\n",
    "fig,axarr = plt.subplots(1,2)\n",
    "axarr[0].set_title(\"x\")\n",
    "axarr[0].imshow(x[0, :, :, 0])\n",
    "axarr[1].set_title(\"x_pad\")\n",
    "axarr[1].imshow(x_pad[0, :, :, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Step of Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
    "    s = np.multiply(a_slice_prev,W)\n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    b = np.squeeze(b)\n",
    "    Z = Z + b\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, \n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape (≈1 line)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
    "    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
    "    n_H = int((n_H_prev + 2*pad - f)/stride) + 1\n",
    "    n_W = int((n_W_prev + 2*pad - f)/stride) + 1\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):               # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i]          # Select ith training example's padded activation\n",
    "        for h in range(n_H):           # loop over vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            vert_start = stride * h\n",
    "            vert_end = vert_start  + f\n",
    "            \n",
    "            for w in range(n_W):       # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
    "                                        \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
    "                    weights = W[:, :, :, c]\n",
    "                    biases  = b[:, :, :, c]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean =\n",
      " 0.5511276474566768\n",
      "Z[0,2,1] =\n",
      " [-2.17796037  8.07171329 -0.5772704   3.36286738  4.48113645 -2.89198428\n",
      " 10.99288867  3.03171932]\n",
      "cache_conv[0][1][2][3] =\n",
      " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 7, 4)\n",
    "W = np.random.randn(3, 3, 4, 8)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\\n\", np.mean(Z))\n",
    "print(\"Z[0,2,1] =\\n\", Z[0, 2, 1])\n",
    "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3, 4, 8), tuple)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape,type(cache_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -2.65112363,  -0.37849177,  -1.97054929,  -1.96235299,\n",
       "           -1.72259872,   0.4676693 ,  -6.43434016,   1.10764994],\n",
       "         [  4.67692928,   4.29865415,  -1.3608031 ,   0.80532859,\n",
       "           -2.88480108,   8.95280034,   5.32627807,  -1.82635258],\n",
       "         [ -2.05881174,   3.40859795,   0.3502282 ,   0.68303626,\n",
       "           -1.88328065,  -1.87480174,   5.8008721 ,   0.0700918 ],\n",
       "         [ -3.50141791,   2.704286  ,   0.28341346,   4.15637411,\n",
       "           -0.46575834,  -0.43668824,  -5.56866106,   1.72288033]],\n",
       "\n",
       "        [[ -2.32126108,   0.91040602,   2.31852532,   0.98842271,\n",
       "            3.31716611,   4.05638832,  -2.48135123,   0.95872443],\n",
       "         [  6.03978907,  -6.96477888,  -1.20799344,   2.68913374,\n",
       "           -4.35744033,  10.59355329,   3.20856901,  13.98735978],\n",
       "         [ -3.01280755,  -2.90226517,  -8.34171936,  -5.26220853,\n",
       "            5.6630696 ,   1.08704033,   2.20430705, -10.73218294],\n",
       "         [ -6.24198266,  -0.53158832,  -3.29654954,  -1.81865997,\n",
       "            0.59196322,   2.51134745,  -4.24924673,   5.21936641]],\n",
       "\n",
       "        [[ -2.22187412,  -0.95259173,  -5.99441273,   0.79147932,\n",
       "            1.16919278,  -0.17321161,  -3.26346299,  -3.62407578],\n",
       "         [ -2.17796037,   8.07171329,  -0.5772704 ,   3.36286738,\n",
       "            4.48113645,  -2.89198428,  10.99288867,   3.03171932],\n",
       "         [-12.49991261,   5.26845833,  -1.67648614,  -8.65695762,\n",
       "          -10.68157258,   6.71492428,   2.83839971,   4.47259772],\n",
       "         [  0.11421092,  -1.90872424,  -3.28117601,   0.89922467,\n",
       "            0.83985348,  -0.25127044,  -0.94409718,   5.17244412]]],\n",
       "\n",
       "\n",
       "       [[[  1.97649814,   2.76743075,  -6.39611007,   2.95378171,\n",
       "           -0.81235239,  -0.53333631,   0.71268871,   4.91385105],\n",
       "         [ -5.14401869,   6.97041391,  -4.53976469,   5.89092653,\n",
       "           -5.74606931,   2.74256558,   3.02124802, -10.04187592],\n",
       "         [  5.53871187,  -8.55886701,  -4.70962135,   2.55966738,\n",
       "           -2.66959504,   5.60010695,  -8.37253342,   4.18848278],\n",
       "         [  0.63364517,  -3.71848223,  -3.67072772,   4.34226476,\n",
       "           -1.21894465,   3.68929452,   5.89166305,   0.94256457]],\n",
       "\n",
       "        [[  2.36049402,  -3.09696204,   8.33521755,   3.04680748,\n",
       "            3.7964542 ,   0.66488788,   1.9935476 ,   1.54396221],\n",
       "         [ -7.73457048,   0.287562  ,   7.97481218,   3.32415996,\n",
       "           -4.07121488,   2.69182963,   4.1356109 ,  -5.16178423],\n",
       "         [ -6.95635186,  -0.10924121,  -4.12526441,   0.62578199,\n",
       "            4.69492086,  -3.52748877,   3.63168271,   0.64007629],\n",
       "         [  7.94980014,   5.71855659,   3.49970333,  12.7718152 ,\n",
       "            8.84959478,   2.37150319,  -1.42531648,  -0.51126641]],\n",
       "\n",
       "        [[ -5.29658283,  -4.20466999,  -6.63067766,  -9.87831724,\n",
       "           -5.32130395,   7.32417919,   2.96011091,   7.60669481],\n",
       "         [ 11.54630784,  -1.93157244,   2.26699242,   7.62184275,\n",
       "            5.40584348,  -2.88837958,  -1.46981877,   7.91314719],\n",
       "         [  5.94067877,   3.50739649,   0.82512202,   4.80655489,\n",
       "           -4.1044945 ,   4.14358541,   0.13194885,   4.35397285],\n",
       "         [  4.91298364,  -1.44499772,   5.9392078 ,  -3.92690408,\n",
       "            2.12840309,   1.27237402,   1.56992581,   0.44270565]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        a_prev_slice = A_prev[i]\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            vert_start = stride * h \n",
    "            vert_end = vert_start + f\n",
    "            \n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
    "                    a_slice_prev = a_prev_slice[vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice. \n",
    "                    # Use an if statement to differentiate the modes. \n",
    "                    # Use np.max and np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_slice_prev)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_slice_prev)\n",
    "                    else:\n",
    "                        print(mode+ \"-type pooling layer NOT Defined\")    \n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A[1, 1] =\n",
      " [[1.96710175 0.84616065 1.27375593]\n",
      " [1.96710175 0.84616065 1.23616403]\n",
      " [1.62765075 1.12141771 1.2245077 ]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A[1, 1] =\n",
      " [[ 0.44497696 -0.00261695 -0.31040307]\n",
      " [ 0.50811474 -0.23493734 -0.23961183]\n",
      " [ 0.11872677  0.17255229 -0.22112197]]\n"
     ]
    }
   ],
   "source": [
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 1, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1, 1] =\\n\", A[1, 1])\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1, 1] =\\n\", A[1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 2, 2, 3)\n",
      "A[0] =\n",
      " [[[1.74481176 0.90159072 1.65980218]\n",
      "  [1.74481176 1.6924546  1.65980218]]\n",
      "\n",
      " [[1.13162939 1.51981682 2.18557541]\n",
      "  [1.13162939 1.6924546  2.18557541]]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 2, 2, 3)\n",
      "A[1] =\n",
      " [[[-0.17313416  0.32377198 -0.34317572]\n",
      "  [ 0.02030094  0.14141479 -0.01231585]]\n",
      "\n",
      " [[ 0.42944926  0.08446996 -0.27290905]\n",
      "  [ 0.15077452  0.28911175  0.00123239]]]\n"
     ]
    }
   ],
   "source": [
    "# Case 2: stride of 2\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[0] =\\n\", A[0])\n",
    "print()\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1] =\\n\", A[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
